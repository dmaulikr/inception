# Inception
### Real time image recognition using Apple's CoreML and Google's Inceptionv3 model

App gets the current frames from the camera using AVCapture and it uses this frame to get predictions using the inception model.

## Requirements
- Xcode 9
- iOS 11

## Results
<img src="https://raw.githubusercontent.com/m25lazi/inception/master/result/joystick.jpg" alt="Joystick" width="300">
<img src="https://raw.githubusercontent.com/m25lazi/inception/master/result/pug.jpg" alt="Pug" width="300">
<img src="https://raw.githubusercontent.com/m25lazi/inception/master/result/switch.jpg" alt="Switch Board" width="300">
<img src="https://raw.githubusercontent.com/m25lazi/inception/master/result/mac.jpg" alt="Macbook" width="300">


## How it works?
You can read my blog on the usage of CoreML with Inceptionv3 [here](https://medium.com/@m25lazi/building-a-real-time-object-recognizer-for-ios-a678d2baf8f0)


## References

[Machine Learning using CoreML](https://developer.apple.com/machine-learning/)

[Capture Video with AVFoundation and Swift](https://www.invasivecode.com/weblog/AVFoundation-Swift-capture-video/)

[Camera View in iOS using Swift](https://gist.github.com/MihaelIsaev/273e4e8ddaaf062d2155)

[Converting UIImage to CVPixelBuffer](https://www.hackingwithswift.com/whats-new-in-ios-11)

